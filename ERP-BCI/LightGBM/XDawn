#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
XDawn features â€” LightGBM training with optional Optuna tuning.

What it does:
  - Loads XDawn features/labels from .npy files
  - (Optionally) prints class weights for reference
  - Trains a baseline LightGBM model and prints metrics
  - (Optional) Runs Optuna to maximize F1('pos') on the test set
  - Retrains with best params and prints metrics
  - (Optional) saves the trained model with pickle

Usage:
  python train_lgbm_xdawn.py \
    --data-dir "/content/drive/MyDrive/2021_VIIT08_P300/Dataset/erp-bci/XDawn" \
    --tune --n-trials 100 --seed 42 --save-model xdawn_lgbm.pkl

Requirements:
  pip install numpy scikit-learn lightgbm
  # for tuning:
  pip install optuna
"""

import os
import argparse
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils.class_weight import compute_class_weight

# LightGBM
from lightgbm import LGBMClassifier


# --------------------- IO ---------------------

def load_arrays(data_dir: str):
    def p(name): return os.path.join(data_dir, f"{name}.npy")
    needed = ["X_train", "X_test", "y_train", "y_test"]
    for name in needed:
        path = p(name)
        if not os.path.isfile(path):
            raise FileNotFoundError(f"Missing file: {path}")
    X_train = np.load(p("X_train"))
    X_test = np.load(p("X_test"))
    y_train = np.load(p("y_train")).reshape(-1)
    y_test = np.load(p("y_test")).reshape(-1)
    return X_train, X_test, y_train, y_test


def print_metrics(title: str, y_true, y_pred):
    print(f"\n{title}")
    print(classification_report(y_true, y_pred))
    print("Confusion matrix:")
    print(confusion_matrix(y_true, y_pred))


def balanced_class_weights(y):
    classes = np.unique(y)
    weights = compute_class_weight(class_weight="balanced", classes=classes, y=y)
    return dict(zip(classes, weights))


# --------------------- Optuna tuning ---------------------

def tune_with_optuna(X_train, y_train, X_test, y_test, n_trials: int, seed: int):
    import optuna
    from optuna.samplers import TPESampler

    def objective(trial: optuna.Trial) -> float:
        params = {
            # mirror the notebook's search space
            "objective": "binary",
            "metric": "binary_logloss",
            "lambda_l1": trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True),
            "lambda_l2": trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True),
            "num_leaves": trial.suggest_int("num_leaves", 2, 256),
            "feature_fraction": trial.suggest_float("feature_fraction", 0.4, 1.0),
            "bagging_fraction": trial.suggest_float("bagging_fraction", 0.4, 1.0),
            "bagging_freq": trial.suggest_int("bagging_freq", 1, 7),
            "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
            # keep defaults for n_estimators, learning_rate, etc.
        }
        model = LGBMClassifier(**params, random_state=seed, n_jobs=-1)
        model.fit(X_train, y_train)
        preds = model.predict(X_test)
        # match notebook: print accuracy each trial, optimize F1 for 'pos'
        from sklearn.metrics import accuracy_score
        print(accuracy_score(y_test, preds))
        return f1_score(y_test, preds, pos_label="pos")

    study = optuna.create_study(direction="maximize", sampler=TPESampler(seed=seed))
    study.optimize(objective, n_trials=n_trials)
    return study


# --------------------- Main ---------------------

def main():
    ap = argparse.ArgumentParser(description="Train LightGBM on XDawn features; optional Optuna tuning.")
    ap.add_argument("--data-dir", type=str, default=".", help="Dir with X_train.npy, X_test.npy, y_train.npy, y_test.npy")
    ap.add_argument("--tune", action="store_true", help="Run Optuna hyperparameter search")
    ap.add_argument("--n-trials", type=int, default=100, help="Number of Optuna trials")
    ap.add_argument("--seed", type=int, default=42, help="Random seed")
    ap.add_argument("--save-model", type=str, default="", help="Path to save final model (.pkl)")
    args = ap.parse_args()

    # Load data
    X_train, X_test, y_train, y_test = load_arrays(args.data_dir)
    print(f"Shapes: X_train {X_train.shape}, X_test {X_test.shape}, y_train {y_train.shape}, y_test {y_test.shape}")

    # Class weights (for reference; not used in the original notebook flow)
    cw = balanced_class_weights(y_train)
    print("Class weights (balanced):", cw)

    # Baseline LightGBM (defaults, like the notebook)
    base = LGBMClassifier(random_state=args.seed, n_jobs=-1)
    base.fit(X_train, y_train)
    y_pred_test = base.predict(X_test)
    print_metrics("Baseline (TEST)", y_test, y_pred_test)

    # Optional tuning with Optuna
    final_model = base
    if args.tune:
        try:
            study = tune_with_optuna(
                X_train, y_train, X_test, y_test,
                n_trials=args.n_trials, seed=args.seed
            )
            print("\nBest trial:")
            print(f"  score  = {study.best_trial.value}")
            print(f"  params = {study.best_trial.params}")
            best = LGBMClassifier(**study.best_trial.params, random_state=args.seed, n_jobs=-1)
            best.fit(X_train, y_train)

            # Evaluate tuned model on TEST and TRAIN (as seen in the notebook)
            y_pred_test = best.predict(X_test)
            print_metrics("Tuned (TEST)", y_test, y_pred_test)

            y_pred_train = best.predict(X_train)
            print_metrics("Tuned (TRAIN)", y_train, y_pred_train)

            final_model = best
        except ImportError:
            print("\n[WARN] Optuna not installed. Install with `pip install optuna` to use --tune.")

    # Optionally save the final model
    if args.save_model:
        import pickle
        out_path = os.path.abspath(args.save_model)
        os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
        with open(out_path, "wb") as f:
            pickle.dump(final_model, f)
        print(f"\nSaved model to: {out_path}")


if __name__ == "__main__":
    main()
