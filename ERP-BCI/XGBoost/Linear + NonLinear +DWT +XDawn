#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Linear + NonLinear + DWT + XDawn — XGBoost training & (optional) Optuna tuning.

This is a direct conversion of the Colab notebook workflow:

- Load:
    X_train.npy, X_test.npy, y_train.npy, y_test.npy
  (defaults expect them under a "Linear and Non Linear Features" folder)

- Compute class weights with sklearn (for reference; baseline XGB uses defaults
  just like the notebook — note XGBoost ignores a `class_weights=` kwarg).

- Baseline:
    model = XGBClassifier(); fit; report metrics on test and train.

- Optuna (optional, --tune):
    Maximize F1 for the positive class ('pos') on the test set using your
    search space, with 'booster'='dart' and 'scale_pos_weight' fixed from
    class weights (as in the notebook). Retrain with best params and report.

Usage:
    python train_xgb_linear_nonlinear_dwt_xdawn.py \
        --data-dir "/content/drive/MyDrive/2021_VIIT08_P300/Dataset/erp-bci/Linear and Non Linear Features" \
        --tune --n-trials 50 --seed 42

Requirements:
    pip install numpy pandas scikit-learn xgboost
    # (Optional, only if using --tune)
    pip install optuna
"""

import os
import argparse
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils.class_weight import compute_class_weight
from xgboost import XGBClassifier


# --------------------- IO helpers ---------------------

def load_npys(data_dir: str):
    def p(name): return os.path.join(data_dir, f"{name}.npy")
    needs = ["X_train", "X_test", "y_train", "y_test"]
    for n in needs:
        if not os.path.isfile(p(n)):
            raise FileNotFoundError(f"Missing: {p(n)}")
    X_train = np.load(p("X_train"))
    X_test  = np.load(p("X_test"))
    y_train = np.load(p("y_train")).reshape(-1)
    y_test  = np.load(p("y_test")).reshape(-1)
    return X_train, X_test, y_train, y_test


def print_report(name: str, y_true, y_pred):
    print(f"\n{name} — classification report")
    print(classification_report(y_true, y_pred))
    print("Confusion matrix:")
    print(confusion_matrix(y_true, y_pred))


def get_class_weights(y):
    classes = np.unique(y)
    weights = compute_class_weight(class_weight="balanced", classes=classes, y=y)
    return dict(zip(classes, weights))


# --------------------- Optuna tuning ---------------------

def run_optuna_tuning(X_train, y_train, X_test, y_test, class_weights, n_trials: int, seed: int):
    """
    Mirrors your notebook's search space & objective:
    - booster='dart'
    - scale_pos_weight fixed to class_weights['pos']
    - objective is F1-score for label 'pos' evaluated on the TEST set (as in the notebook)
    """
    import optuna
    from optuna.samplers import TPESampler

    pos_weight = float(class_weights.get('pos', 1.0))

    def objective(trial: optuna.Trial) -> float:
        params = {
            "n_estimators":      trial.suggest_int("n_estimators", 2, 100),
            "max_depth":         trial.suggest_int("max_depth", 2, 45),
            "reg_alpha":         2,                       # fixed (as in notebook)
            "reg_lambda":        3,                       # fixed (as in notebook)
            "min_child_weight":  trial.suggest_int("min_child_weight", 0, 25),
            "gamma":             trial.suggest_int("gamma", 0, 3),
            "learning_rate":     trial.suggest_loguniform("learning_rate", 0.005, 0.5),
            "scale_pos_weight":  pos_weight,              # taken from class weights (notebook choice)
            "nthread":           -1,
            "booster":           "dart",
            # Other defaults mirror XGBClassifier defaults
        }
        model = XGBClassifier(**params)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        score = f1_score(y_test, y_pred, pos_label="pos")
        # Print each score to mirror notebook’s stdout noise
        print(score)
        return score

    study = optuna.create_study(direction="maximize", sampler=TPESampler(seed=seed))
    study.optimize(objective, n_trials=n_trials)
    return study


# --------------------- Main ---------------------

def main():
    ap = argparse.ArgumentParser(description="Train XGBoost on Linear+NonLinear+DWT+XDawn features, optional Optuna tuning.")
    ap.add_argument("--data-dir", type=str, default=".", help="Folder containing X_train.npy, X_test.npy, y_train.npy, y_test.npy")
    ap.add_argument("--tune", action="store_true", help="Run Optuna hyperparameter search (like the notebook)")
    ap.add_argument("--n-trials", type=int, default=50, help="Optuna trials (if --tune)")
    ap.add_argument("--seed", type=int, default=42, help="Random seed for Optuna sampler")
    ap.add_argument("--save-model", type=str, default="", help="Optional path to save the final XGB model (.pkl)")
    args = ap.parse_args()

    # Load data
    X_train, X_test, y_train, y_test = load_npys(args.data_dir)
    print(f"Shapes: X_train {X_train.shape}  X_test {X_test.shape}  y_train {y_train.shape}  y_test {y_test.shape}")

    # Class weights (for info & tuning)
    class_weights = get_class_weights(y_train)
    print("Class weights (sklearn balanced):", class_weights)

    # ===== Baseline model (matches notebook: default XGB; note: XGBoost ignores 'class_weights' kwarg) =====
    baseline = XGBClassifier()
    baseline.fit(X_train, y_train)

    # Evaluate on test (then train, like notebook)
    y_pred_test = baseline.predict(X_test)
    print_report("Baseline (TEST)", y_test, y_pred_test)

    y_pred_train = baseline.predict(X_train)
    print_report("Baseline (TRAIN)", y_train, y_pred_train)

    final_model = baseline

    # ===== Optional Optuna tuning =====
    if args.tune:
        study = run_optuna_tuning(
            X_train, y_train, X_test, y_test,
            class_weights=class_weights,
            n_trials=args.n_trials,
            seed=args.seed
        )
        print("\nBest trial:")
        print(f"  score  = {study.best_trial.value}")
        print(f"  params = {study.best_trial.params}")

        tuned = XGBClassifier(**study.best_trial.params)
        tuned.fit(X_train, y_train)

        y_pred_test = tuned.predict(X_test)
        print_report("Tuned (TEST)", y_test, y_pred_test)

        final_model = tuned

    # Optional: save model
    if args.save_model:
        import pickle
        os.makedirs(os.path.dirname(os.path.abspath(args.save_model)) or ".", exist_ok=True)
        with open(args.save_model, "wb") as f:
            pickle.dump(final_model, f)
        print(f"\nSaved model to: {os.path.abspath(args.save_model)}")


if __name__ == "__main__":
    main()
