#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
XDawn features â€” XGBoost training with optional Optuna tuning.

Converted from the provided Colab notebook. It:
  - Loads XDawn tangent-space features and labels from .npy files
  - Computes class weights
  - Trains a baseline XGBoost model and prints metrics
  - (Optional) Runs Optuna to maximize F1('pos') on the test set using your search space
  - Retrains with the best params and prints metrics

Usage example:
  python train_xgb_xdawn.py \
    --data-dir "/content/drive/MyDrive/2021_VIIT08_P300/Dataset/erp-bci/XDawn" \
    --tune --n-trials 20 --seed 42 --save-model xdawn_xgb.pkl

Requirements:
  pip install numpy scikit-learn xgboost
  # for tuning:
  pip install optuna
"""

import os
import argparse
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, f1_score
from sklearn.utils.class_weight import compute_class_weight
from xgboost import XGBClassifier


# --------------------- Helpers ---------------------

def load_arrays(data_dir: str):
    def p(name): return os.path.join(data_dir, f"{name}.npy")
    for name in ("X_train", "X_test", "y_train", "y_test"):
        path = p(name)
        if not os.path.isfile(path):
            raise FileNotFoundError(f"Missing file: {path}")
    X_train = np.load(p("X_train"))
    X_test = np.load(p("X_test"))
    y_train = np.load(p("y_train")).reshape(-1)
    y_test = np.load(p("y_test")).reshape(-1)
    return X_train, X_test, y_train, y_test


def print_metrics(title: str, y_true, y_pred):
    print(f"\n{title}")
    print(classification_report(y_true, y_pred))
    print("Confusion matrix:")
    print(confusion_matrix(y_true, y_pred))


def balanced_class_weights(y):
    classes = np.unique(y)
    weights = compute_class_weight(class_weight="balanced", classes=classes, y=y)
    return dict(zip(classes, weights))


# --------------------- Optuna tuning ---------------------

def tune_with_optuna(X_train, y_train, X_test, y_test, pos_weight: float, n_trials: int, seed: int):
    """
    Mirrors the notebook's intent:
      - booster='dart'
      - scale_pos_weight fixed from computed class weights (for 'pos')
      - search space over n_estimators, max_depth, reg_alpha, reg_lambda,
        min_child_weight, gamma, learning_rate
      - objective: F1 score for the 'pos' class on the TEST set
    """
    import optuna
    from optuna.samplers import TPESampler

    def objective(trial: optuna.Trial) -> float:
        params = {
            "n_estimators":     trial.suggest_int("n_estimators", 2, 100),
            "max_depth":        trial.suggest_int("max_depth", 2, 15),
            "reg_alpha":        trial.suggest_int("reg_alpha", 1, 5),
            "reg_lambda":       trial.suggest_int("reg_lambda", 1, 5),
            "min_child_weight": trial.suggest_int("min_child_weight", 0, 25),
            # The notebook outputs show gamma up to 10, so we search 0..10:
            "gamma":            trial.suggest_int("gamma", 0, 10),
            "learning_rate":    trial.suggest_loguniform("learning_rate", 0.005, 0.5),
            "scale_pos_weight": float(pos_weight),
            "nthread":          -1,
            "booster":          "dart",
        }
        model = XGBClassifier(**params)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        score = f1_score(y_test, y_pred, pos_label="pos")
        print(score)  # match notebook's per-trial logging
        return score

    study = optuna.create_study(direction="maximize", sampler=TPESampler(seed=seed))
    study.optimize(objective, n_trials=n_trials)
    return study


# --------------------- Main ---------------------

def main():
    ap = argparse.ArgumentParser(description="Train XGB on XDawn features; optional Optuna tuning.")
    ap.add_argument("--data-dir", type=str, default=".", help="Directory with X_train.npy, X_test.npy, y_train.npy, y_test.npy")
    ap.add_argument("--tune", action="store_true", help="Run Optuna hyperparameter search (like the notebook)")
    ap.add_argument("--n-trials", type=int, default=20, help="Number of Optuna trials")
    ap.add_argument("--seed", type=int, default=42, help="Random seed for Optuna sampler")
    ap.add_argument("--save-model", type=str, default="", help="Optional path to save the final XGB model (.pkl)")
    args = ap.parse_args()

    # Load data
    X_train, X_test, y_train, y_test = load_arrays(args.data_dir)
    print(f"Shapes: X_train {X_train.shape}, X_test {X_test.shape}, y_train {y_train.shape}, y_test {y_test.shape}")

    # Class weights
    cw = balanced_class_weights(y_train)
    print("Class weights (balanced):", cw)
    pos_w = float(cw.get("pos", 1.0))

    # Baseline model (the notebook passed class_weights=..., which XGBoost ignores;
    # we keep defaults here to reflect effective behavior.)
    baseline = XGBClassifier()
    baseline.fit(X_train, y_train)

    y_pred_test = baseline.predict(X_test)
    print_metrics("Baseline (TEST)", y_test, y_pred_test)

    # Optional: tuning
    final_model = baseline
    if args.tune:
        try:
            study = tune_with_optuna(
                X_train, y_train, X_test, y_test,
                pos_weight=pos_w, n_trials=args.n_trials, seed=args.seed
            )
        except ImportError:
            print("\n[WARN] Optuna not installed. Install with `pip install optuna` to use --tune.")
            study = None

        if study is not None:
            print("\nBest trial:")
            print(f"  score  = {study.best_trial.value}")
            print(f"  params = {study.best_trial.params}")

            tuned = XGBClassifier(**study.best_trial.params)
            tuned.fit(X_train, y_train)

            # Evaluate tuned model on TEST and TRAIN (as in the notebook)
            y_pred_test = tuned.predict(X_test)
            print_metrics("Tuned (TEST)", y_test, y_pred_test)

            y_pred_train = tuned.predict(X_train)
            print_metrics("Tuned (TRAIN)", y_train, y_pred_train)

            final_model = tuned

    # Optionally save the final model
    if args.save_model:
        import pickle
        os.makedirs(os.path.dirname(os.path.abspath(args.save_model)) or ".", exist_ok=True)
        with open(args.save_model, "wb") as f:
            pickle.dump(final_model, f)
        print(f"\nSaved model to: {os.path.abspath(args.save_model)}")


if __name__ == "__main__":
    main()
